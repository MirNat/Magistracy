{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №13 по курсу «Машинное обучение»: Online learning\n",
    "### Выполнила Мирейко Наталья\n",
    "\n",
    "\n",
    "### Задание 1\n",
    "\n",
    "Доказать, что MSOA(H) = Ldim(H).\n",
    "    \n",
    "### Решение\n",
    "\n",
    "#### Доказательство. \n",
    "\n",
    "Докажем, что для SOA выполняется $$M_{SOA}(H) \\leq Ldim(H).$$ \n",
    "Понятно, что $Ldim(V_{t})$ не может возрастать, так как класс гипотез не увеличивается по ходу алгоритма. Каждый раз, когда алгоритм SOA делает ошибку, выполняется $$Ldim(V_{t+1}) \\leq Ldim(V_{t})-1.$$ \n",
    "Докажем это от противного. Предположим, что $$Ldim(V_{t+1})=Ldim(V_{t}).$$ Из этого слеедует, что $$Ldim(V_{t}^{r})=Ldim(V_{t})$$ для $r=1$ и $r=0$. А значит можно построить раскрашенное дерево (shattered tree) для $LDim(V_t)$ глубины $Ldim(V_{t})+1$ - получаем противоречие. Таким образом, справедливо $Ldim(V_{t+1}) \\leq Ldim(V_{t})-1$, что означает, что после каждой ошибки $LDim(V_t)$ уменьшается хотя бы на единицу, а значит, количество ошибок алгоритма соответсвует $M_{SOA}(H) \\leq Ldim(H)$.\n",
    "\n",
    "\n",
    "Теперь докажем, что $$M_{A} \\geq Ldim(H).$$ Пусть $T = Ldim(H)$ и есть последовательность вершин $(v_{1},v_{2},...,v_{2^{T}-1})$, удовлетворяющих определению $Ldim$, а значит существует разукрашиваемое дерево высоты $T$. Алгоритм ошибется ровно $T$ раз, если природа для всех $t = 1,...,T$ будет указывать для $v_{i_{t}}$ объекта метку, противоположную предсказанию алгоритма. То есть не существует алгоритма у которого $M_{A} < Ldim(H)$.\n",
    "\n",
    "Таким образом, из доказанных утверждений $$M_{SOA}(H) \\leq Ldim(H) и $M_{A} \\geq Ldim(H)$ следует, что $M_{SOA}(H) = Ldim(H)$.\n",
    "\n",
    "### Задание 2\n",
    "\n",
    "Доказать, что разница между Ldim(H) и VCdim(H) может быть сколь угодно большой.  \n",
    "      \n",
    "### Решение\n",
    "\n",
    "#### Доказательство.\n",
    "\n",
    "Для доказательства достаточно привести класс гипотез, для которых это утверждение верно. Таким классом гипотиз является семейство пороговых функций:\n",
    "\n",
    "$$H=\\{h_{\\alpha}: \\alpha\\in R\\}$, где $h_{\\alpha}(x)=1_{[x<\\alpha]}$$ , и $Ldim(H) = \\infty$, $VCdim(H) = 1$, $|Ldim(H) - VCdim(H)|=\\infty$\n",
    "\n",
    "\n",
    "### Задание 3\n",
    "      \n",
    "Найти класс H, что алгоритм Consistent делает на нём $|H| − 1$ ошибку.\n",
    "          \n",
    "### Решение\n",
    "    \n",
    "Рассмотрим $n$ объектов $X=\\{x_{1},...x_{n}\\}$ таких, что класс этих объектов равен $0$ для $x_{1},...x_{n-1}$, и равен $1$ для $x_{n}$. Также рассмотрим множество гипотез $H=\\{h_{i} | h_{i}(x_{j})=1, если i=j; h_{i}(x_{j}) = 0, если i\\neq j  \\}$, $|H|=n$. Для того, чтобы алгоритм совершил ровно $|H| − 1$ ошибку нужно, чтобы при каждой ошибке алгоритм отбрасывал ровно одну гипотезу из класса, и единственная гипотеза, которая дает правильный ответ на всех объектах, была последней. Приведу самый очевидный пример: пусть мы выбрали гипотезы случайно в отсортированном по возрастанию индекса порядке, и последняя гипотеза $h_{n}$ дает правильный ответ на всех объектах. И пусть объекты $x_{i}$ также случайным  образом приходят в отсортированном по индексу порядку. Тогда на $i$-ой итерации, $i\\neq n$ , будет выбираться $i$-ая гипотеза проверяться на $i$-ом объекте, а затем исключаться из множества далее рассматриваемых гипотез. И на последней итерации останется единственная гипотеза $h_{n}=h^{*}$, которая и дает правильный ответ на всех объектах. Таким образом, общее число ошибок при таком псевдо-случайном выборе гипотезы будет равно $|H| − 1$.\n",
    "    \n",
    "### Задание 4\n",
    "\n",
    "Найти класс H, что алгоритм Halving делает на нём ровно $log2(|H|)$ ошибок.\n",
    "      \n",
    "### Решение\n",
    "\n",
    "Алгоритм совершит ровно $log_{2}(|H|)$ ошибок, если подобрать такую последовательность и такой класс гипотез, что на каждой итерации алгоритм ошибется и после каждой итерации $V_{t}$ будет уменьшаться вдвое за счет того, что ровно половина гипотез проголосует за положительный класс, а вторая за отрицательный. А когда возникает такая неоднозначная ситуация, будем предсказывать метку 1. Чтобы получить ровно логарифм ошибок, размер класса гипотез должен быть кратным степени двойки, поэтому рассмотрим множество бинарных векторов длины $n$, $n=2^{m}$. Рассмотрим множество гипотез  $H=\\{h_{i}=x_{i},i=1,...,n\\}$ ($i$-ая координата вектора) и истинную гипотезу $h^{*}=h_{1}=x_{1}$. Пусть первым \"случайно\" приходит объект, у которого на $0,...,n/2$  местах стоят $0$, а на остальных местах стоят $1$. Тогда первые $n/2$ гипотезы $h_{1},...,h_{n/2}$ ответят $\"0\"$, а остальные $n/2$  гипотез $h_{n/2+1},...,h_{n}$ ответят $\"1\"$. В такой ситуации мы говорим, что объект принадлежит классу 1, а значит гипотезы $h_{n/2+1},...,h_{n}$  будут исключены. А на $i$-ом шаге приходит объект, у которого на $0,...,n/(2^{i})$  местах стоят $0$, а на остальных местах $1$. Тогда  $n/(2^{i})$ гипотезы $h_{1},...,h_{n/(2^{i})}$ ответят $\"0\"$, а $n/(2^{i})$ гипотезы $h_{n/(2^{i})+1},...,h_{n/(2^{i-1})}$ ответят $\"1\"$. В такой ситуации мы говорим, что объект принадлежит классу 1, а значит гипотезы    $h_{n/(2^{i})+1},...,h_{n/(2^{i-1})}$ будут исключены. Таким образом, алгоритм придет к гипотезе $h^{*}$, сделав ровно $log_{2}(|H|)$ ошибок.\n",
    "\n",
    "### Задание 5\n",
    "\n",
    "[Бонус] Почему в online perceptron не взять в качестве суррогатной лосс-функции ft(w) = 0, если алгоритм не ошибается, и ft(w) = 1, если ошибается? Чем плох такой выбор?\n",
    "      \n",
    "### Решение\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
